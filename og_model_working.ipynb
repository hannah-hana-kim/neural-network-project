{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 11:40:40.323994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/kendallgilbert/anaconda3/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Obtaining images of R ...\n",
      "Obtaining images of U ...\n",
      "Obtaining images of I ...\n",
      "Obtaining images of N ...\n",
      "Obtaining images of G ...\n",
      "Obtaining images of Z ...\n",
      "Obtaining images of T ...\n",
      "Obtaining images of S ...\n",
      "Obtaining images of A ...\n",
      "Obtaining images of F ...\n",
      "Obtaining images of O ...\n",
      "Obtaining images of H ...\n",
      "Obtaining images of del ...\n",
      "Obtaining images of nothing ...\n",
      "Obtaining images of space ...\n",
      "Obtaining images of M ...\n",
      "Obtaining images of J ...\n",
      "Obtaining images of C ...\n",
      "Obtaining images of D ...\n",
      "Obtaining images of V ...\n",
      "Obtaining images of Q ...\n",
      "Obtaining images of X ...\n",
      "Obtaining images of E ...\n",
      "Obtaining images of B ...\n",
      "Obtaining images of K ...\n",
      "Obtaining images of L ...\n",
      "Obtaining images of Y ...\n",
      "Obtaining images of P ...\n",
      "Obtaining images of W ...\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "# Define train_dir\n",
    "train_images = os.path.join(path, 'asl_alphabet_train', 'asl_alphabet_train')\n",
    "\n",
    "# Getting Images\n",
    "def get_data(data_dir) :\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    dir_list = os.listdir(data_dir)\n",
    "    for i in range(len(dir_list)):\n",
    "        print(\"Obtaining images of\", dir_list[i], \"...\")\n",
    "        for image in os.listdir(data_dir + \"/\" + dir_list[i]):\n",
    "            img = cv2.imread(data_dir + '/' + dir_list[i] + '/' + image)\n",
    "            img = cv2.resize(img, (32, 32))\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "X, y = get_data(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "           'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (69600, 32, 32, 3), Test data shape: (17400, 32, 32, 3)\n",
      "Training labels shape: (69600,), Test labels shape: (17400,)\n"
     ]
    }
   ],
   "source": [
    "# Split into Training and Test\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize the images (scale pixel values to range [0, 1])\n",
    "X_normalized = X.astype('float32') / 255.0\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shapes\n",
    "print(f\"Training data shape: {X_train.shape}, Test data shape: {X_test.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}, Test labels shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_encoded = to_categorical(y_train, num_classes=len(labels))\n",
    "y_test_encoded = to_categorical(y_test, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740/1740 [==============================] - 150s 86ms/step - loss: 2.9432 - accuracy: 0.1600 - val_loss: 2.8730 - val_accuracy: 0.1438\n"
     ]
    }
   ],
   "source": [
    "classes = 29\n",
    "batch = 32\n",
    "epochs = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, batch_size=batch, epochs=epochs, validation_split=0.2, shuffle = True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544/544 [==============================] - 15s 28ms/step - loss: 2.8438 - accuracy: 0.1540\n",
      "Test Accuracy: 0.1539655178785324\n",
      "Test loss 2.8437795639038086\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test_encoded)\n",
    "print('Test Accuracy:', test_acc)\n",
    "print('Test loss', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = load_model('test1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Predicted class: U\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model('atest.h5')\n",
    "\n",
    "# Define the labels\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "          'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "          'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "\n",
    "# Load the image and preprocess it\n",
    "img_path = 'ASL_Data/asl_alphabet_train/asl_alphabet_train/A/A329.jpg' \n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Resize the image to the target size (32x32)\n",
    "img_resized = cv2.resize(img, (32, 32))\n",
    "\n",
    "# Convert the image from BGR to RGB (OpenCV loads images in BGR by default)\n",
    "img_resized_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Normalize the image (scale pixel values between 0 and 1)\n",
    "img_resized_rgb = img_resized_rgb / 255.0\n",
    "\n",
    "# Expand dimensions to match model's input (add batch size dimension)\n",
    "img_array = np.expand_dims(img_resized_rgb, axis=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class index (highest probability)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map the predicted index to the corresponding label\n",
    "predicted_label = labels[predicted_class_index[0]]\n",
    "\n",
    "# Print the predicted label\n",
    "print(f\"Predicted class: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
