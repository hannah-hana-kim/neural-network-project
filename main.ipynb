{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "format:\n",
    "    html:\n",
    "        embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Final Project\n",
    "author: Hannah Kim, Kendall Gilbert\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# check the versions\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/asl_alphabet_train/asl_alphabet_train/.DS_Store \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/R \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/U \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/I \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/N \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/G \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/Z \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/T \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/S \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/A \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/F \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/O \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/H \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/del \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/nothing \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/space \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/M \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/J \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/C \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/D \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/V \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/Q \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/X \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/E \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/B \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/K \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/L \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/Y \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/P \n",
      "\n",
      "data/asl_alphabet_train/asl_alphabet_train/W \n",
      "\n",
      "Done loading images\n"
     ]
    }
   ],
   "source": [
    "# define the path to the dataset\n",
    "path = 'data/asl_alphabet_train/asl_alphabet_train'\n",
    "images_size=(224, 224)\n",
    "\n",
    "# initialize the images and labels\n",
    "images = []\n",
    "labels=[]\n",
    "\n",
    "# loop over the folder\n",
    "for folder in os.listdir(path):\n",
    "    class_folder = os.path.join(path, folder)\n",
    "    print(class_folder, \"\\n\")\n",
    "    if os.path.isdir(class_folder): # check if it's a folder\n",
    "        # loop through the images in the class folder\n",
    "        for image in os.listdir(class_folder):\n",
    "            image_path = os.path.join(class_folder, image)\n",
    "            # read the image\n",
    "            img = cv2.imread(image_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert the image to RGB\n",
    "                img = cv2.resize(img, images_size)\n",
    "                img = img.astype('float32') / 255.0 # normalize\n",
    "                images.append(img)\n",
    "                labels.append(folder)\n",
    "\n",
    "print(\"Done loading images\")\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# double check\n",
    "print(f\"Number of images: {len(images)}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n",
    "\n",
    "# encode labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN model\n",
    "model = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)), # kernel: 3 x 3 matrix\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(len(np.unique(labels)), activation='softmax') # multi-class classification\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
